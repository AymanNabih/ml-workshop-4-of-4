{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline\n",
    "#plt.rcParams[\"figure.dpi\"] = 300\n",
    "plt.rcParams[\"savefig.dpi\"] = 300\n",
    "plt.rcParams[\"savefig.bbox\"] = \"tight\"\n",
    "\n",
    "np.set_printoptions(precision=3, suppress=True)\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import scale, StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tree -dL 2 aclImdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_files\n",
    "\n",
    "reviews_train = load_files(\"aclImdb/train/\")\n",
    "# load_files returns a bunch, containing training texts and training labels\n",
    "text_trainval, y_trainval = reviews_train.data, reviews_train.target\n",
    "print(\"type of text_trainval: {}\".format(type(text_trainval)))\n",
    "print(\"length of text_trainval: {}\".format(len(text_trainval)))\n",
    "print(\"text_trainval[1]:\\n{}\".format(text_trainval[1].decode()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(text_train[11451].decode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(text_train[16019].decode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_train = [doc.replace(b\"<br />\", b\" \") for doc in text_train]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get some data from european parliament"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(\"http://www.europarl.europa.eu/meps/en/xml.html?query=full&filter=all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_xml = ET.fromstring(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "members_xml = data_xml.getchildren()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "members_dict = [{i.tag: i.text for i in member} for member in members_xml]\n",
    "members = pd.DataFrame(members_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "members.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "malory = [\"Do you want ants?\",\n",
    "          \"Because that’s how you get ants.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vect = CountVectorizer()\n",
    "vect.fit(malory)\n",
    "print(vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = vect.transform(malory)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(malory)\n",
    "print(vect.inverse_transform(X)[0])\n",
    "print(vect.inverse_transform(X)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_files\n",
    "\n",
    "reviews_train = load_files(\"aclImdb/train/\")\n",
    "# load_files returns a bunch, containing training texts and training labels\n",
    "text_trainval, y_trainval = reviews_train.data, reviews_train.target\n",
    "print(\"type of text_trainval: {}\".format(type(text_trainval)))\n",
    "print(\"length of text_trainval: {}\".format(len(text_trainval)))\n",
    "print(\"text_trainval[1]:\\n{}\".format(text_trainval[1].decode()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_trainval = [doc.replace(b\"<br />\", b\" \") for doc in text_trainval]\n",
    "\n",
    "text_train, text_val, y_train, y_val = train_test_split(\n",
    "    text_trainval, y_trainval, stratify=y_trainval, random_state=0)\n",
    "vect = CountVectorizer()\n",
    "X_train = vect.fit_transform(text_train)\n",
    "X_val = vect.transform(text_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = vect.get_feature_names()\n",
    "print(feature_names[:10])\n",
    "print(feature_names[20000:20020])\n",
    "print(feature_names[::2000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "lr = LogisticRegressionCV().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.C_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.score(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_important_features(coef, feature_names, top_n=20, ax=None, rotation=60):\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "    inds = np.argsort(coef)\n",
    "    low = inds[:top_n]\n",
    "    high = inds[-top_n:]\n",
    "    important = np.hstack([low, high])\n",
    "    myrange = range(len(important))\n",
    "    colors = ['red'] * top_n + ['blue'] * top_n\n",
    "    \n",
    "    ax.bar(myrange, coef[important], color=colors)\n",
    "    ax.set_xticks(myrange)\n",
    "    ax.set_xticklabels(feature_names[important], rotation=rotation, ha=\"right\")\n",
    "    ax.set_xlim(-.7, 2 * top_n)\n",
    "    ax.set_frame_on(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 6))\n",
    "plot_important_features(lr.coef_.ravel(), np.array(feature_names), top_n=20, rotation=40)\n",
    "ax = plt.gca()\n",
    "plt.savefig(\"images/coefficients.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorization options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(vect.token_pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer(token_pattern=r\"\\b\\w+\\b\")\n",
    "vect.fit(malory)\n",
    "print(vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer(token_pattern=r\"\\b\\w[\\w’]+\\b\")\n",
    "# not actually an apostroph but some unicode pattern\n",
    "# because I copy & pasted the quote\n",
    "vect.fit(malory)\n",
    "print(vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer(stop_words='english')\n",
    "vect.fit(malory)\n",
    "print(vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "print(list(ENGLISH_STOP_WORDS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"well\" in ENGLISH_STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer(min_df=2)\n",
    "vect.fit(malory)\n",
    "print(vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer(max_features=4)\n",
    "vect.fit(malory)\n",
    "print(vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer(min_df=2)\n",
    "X_train_df2 = vect.fit_transform(text_train)\n",
    "X_val_df2 = vect.transform(text_val)\n",
    "print(X_train.shape)\n",
    "print(X_train_df2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer(min_df=4)\n",
    "X_train_df4 = vect.fit_transform(text_train)\n",
    "X_val_df4 = vect.transform(text_val)\n",
    "print(X_train.shape)\n",
    "print(X_train_df2.shape)\n",
    "print(X_train_df4.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegressionCV().fit(X_train_df4, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.C_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.score(X_val_df4, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# n-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(ngram_range=(1, 1)).fit(malory)\n",
    "print(\"Vocabulary size: {}\".format(len(cv.vocabulary_)))\n",
    "print(\"Vocabulary:\\n{}\".format(cv.get_feature_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(ngram_range=(2, 2)).fit(malory)\n",
    "print(\"Vocabulary size: {}\".format(len(cv.vocabulary_)))\n",
    "print(\"Vocabulary:\\n{}\".format(cv.get_feature_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(ngram_range=(1, 2)).fit(malory)\n",
    "print(\"Vocabulary size: {}\".format(len(cv.vocabulary_)))\n",
    "print(\"Vocabulary:\\n{}\".format(cv.get_feature_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ngram_range in [(1, 1), (1, 2), (1, 3), (1, 4)]:\n",
    "    \n",
    "    cv = CountVectorizer(ngram_range=ngram_range, min_df=4).fit(text_train)\n",
    "    print(\"Vocabulary size {} (min_df=4): {}\".format(ngram_range, len(cv.vocabulary_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(ngram_range=(1, 4)).fit(text_train_sub)\n",
    "print(\"Vocabulary size 1-4gram: {}\".format(len(cv.vocabulary_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(ngram_range=(1, 2), min_df=4).fit(text_train_sub)\n",
    "print(\"Vocabulary size (1, 2), min_df=4: {}\".format(len(cv.vocabulary_)))\n",
    "cv = CountVectorizer(ngram_range=(1, 2), min_df=4, stop_words=\"english\").fit(text_train_sub)\n",
    "print(\"Vocabulary size (1, 2), stopwords, min_df=4: {}\".format(len(cv.vocabulary_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv4 = CountVectorizer(ngram_range=(4, 4), min_df=4).fit(text_train)\n",
    "cv4sw = CountVectorizer(ngram_range=(4, 4), min_df=4, stop_words=\"english\").fit(text_train)\n",
    "print(len(cv4.get_feature_names()))\n",
    "print(len(cv4sw.get_feature_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cv4.get_feature_names()[::1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cv4sw.get_feature_names()[::10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bla = cv4sw.transform(text_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.array(cv4sw.get_feature_names())[np.argsort(np.array(bla.sum(axis=0)).ravel())[::-1][:50]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(\"\".join(cv4sw.get_feature_names()).split()).value_counts()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect3 = CountVectorizer(ngram_range=(1, 3), min_df=4)\n",
    "X_train3 = vect3.fit_transform(text_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr3 = LogisticRegressionCV().fit(X_train3, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr3.C_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val3 = vect3.transform(text_val)\n",
    "lr3.score(X_val3, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 4))\n",
    "plot_important_features(lr3.coef_.ravel(), np.array(vect3.get_feature_names()), top_n=40, rotation=70)\n",
    "plt.title(\"Stopwords included (1-3 gram)\")\n",
    "plt.savefig(\"images/stopwords_1.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect3sw = CountVectorizer(ngram_range=(1, 3), min_df=4, stop_words='english')\n",
    "X_train3sw = vect3sw.fit_transform(text_train)\n",
    "lr3sw = LogisticRegressionCV().fit(X_train3sw, y_train)\n",
    "X_val3sw = vect3sw.transform(text_val)\n",
    "lr3sw.score(X_val3sw, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.C_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 4))\n",
    "plot_important_features(lr3sw.coef_.ravel(), np.array(vect3sw.get_feature_names()), top_n=40)\n",
    "plt.title(\"Stopwords excluded (1-3 gram)\")\n",
    "plt.savefig(\"images/stopwords_2.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_stopwords = set(ENGLISH_STOP_WORDS)\n",
    "my_stopwords.remove(\"well\")\n",
    "my_stopwords.remove(\"not\")\n",
    "my_stopwords.add(\"ve\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect3msw = CountVectorizer(ngram_range=(1, 3), min_df=4, stop_words=my_stopwords)\n",
    "X_train3msw = vect3msw.fit_transform(text_train)\n",
    "lr3msw = LogisticRegressionCV().fit(X_train3msw, y_train)\n",
    "X_val3msw = vect3msw.transform(text_val)\n",
    "lr3msw.score(X_val3msw, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 4))\n",
    "plt.title(\"Adjusted Stopwords (1-3 gram)\")\n",
    "plot_important_features(lr3msw.coef_.ravel(), np.array(vect3msw.get_feature_names()), top_n=40)\n",
    "plt.savefig(\"images/stopwords_3.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "malory_tfidf = TfidfVectorizer().fit_transform(malory)\n",
    "malory_tfidf.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "malory_tfidf = make_pipeline(CountVectorizer(), TfidfTransformer()).fit_transform(malory)\n",
    "malory_tfidf.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer(ngram_range=(1, 3), min_df=4, stop_words=my_stopwords)\n",
    "X_train_tfidf = tfidf.fit_transform(text_train)\n",
    "lr = LogisticRegressionCV().fit(X_train_tfidf, y_train)\n",
    "X_val_tfidf = tfidf.transform(text_val)\n",
    "lr.score(X_val_tfidf, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Character n-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(malory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(ngram_range=(2, 3), analyzer=\"char\").fit(malory)\n",
    "print(\"Vocabulary size: {}\".format(len(cv.vocabulary_)))\n",
    "print(\"Vocabulary:\\n{}\".format(cv.get_feature_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(ngram_range=(2, 3), analyzer=\"char_wb\").fit(malory)\n",
    "print(\"Vocabulary size: {}\".format(len(cv.vocabulary_)))\n",
    "print(\"Vocabulary:\\n{}\".format(cv.get_feature_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_vect = CountVectorizer(ngram_range=(2, 5), min_df=4, analyzer=\"char_wb\")\n",
    "X_train_char = char_vect.fit_transform(text_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(char_vect.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_char = LogisticRegressionCV().fit(X_train_char, y_train)\n",
    "X_val_char = char_vect.transform(text_val)\n",
    "lr_char.score(X_val_char, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 4))\n",
    "plot_important_features(lr_char.coef_.ravel(), np.array(char_vect.get_feature_names()), top_n=40)\n",
    "plt.savefig(\"images/imdb_char_ngrams.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting nationalities from names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "members.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "members.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_mem = members.country\n",
    "data_mem = members.fullName\n",
    "plt.figure(figsize=(8, 4))\n",
    "(y_mem.value_counts() / y_mem.size).plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_mem.value_counts()[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "large = y_mem.value_counts()[:8].index\n",
    "large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = y_mem.isin(large)\n",
    "data_mem = data_mem[mask]\n",
    "y_mem = y_mem[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(y_mem.value_counts() / y_mem.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_mem.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_mem_train, text_mem_test, y_mem_train, y_mem_test = train_test_split(data_mem, y_mem, stratify=y_mem, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_pipe = make_pipeline(CountVectorizer(), LogisticRegressionCV())\n",
    "cross_val_score(bow_pipe, text_mem_train, y_mem_train, cv=5, scoring='f1_macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_pipe = make_pipeline(CountVectorizer(analyzer=\"char_wb\"), LogisticRegressionCV())\n",
    "cross_val_score(char_pipe, text_mem_train, y_mem_train, cv=5, scoring='f1_macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_pipe = make_pipeline(CountVectorizer(analyzer=\"char_wb\", ngram_range=(1, 4)), LogisticRegressionCV())\n",
    "cross_val_score(char_pipe, text_mem_train, y_mem_train, cv=5, scoring='f1_macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_pipe.fit(text_mem_train, y_mem_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = char_pipe.named_steps['logisticregressioncv']\n",
    "feature_names = np.array(char_pipe.named_steps['countvectorizer'].get_feature_names())\n",
    "n_classes = len(lr.classes_)\n",
    "fig, axes = plt.subplots(n_classes // 3 + 1, 3, figsize=(10, 4))\n",
    "for ax, coef, label in zip(axes.ravel(), lr.coef_, lr.classes_):\n",
    "    ax.set_title(label)\n",
    "    plot_important_features(coef, feature_names, top_n=10, ax=ax)\n",
    "    \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "param_grid = {\"logisticregression__C\": [100, 10, 1, 0.1, 0.001],\n",
    "              \"countvectorizer__ngram_range\": [(1, 1), (1, 2), (1, 5), (1, 7),\n",
    "                                               (2, 3), (2, 5), (3, 8), (5, 5)],\n",
    "              \"countvectorizer__min_df\": [1, 2, 3],\n",
    "              \"normalizer\": [None, Normalizer()]\n",
    "             }\n",
    "grid = GridSearchCV(make_pipeline(CountVectorizer(analyzer=\"char\"), Normalizer(), LogisticRegression()),\n",
    "                    param_grid=param_grid, cv=10, scoring=\"f1_macro\"\n",
    "                   )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.fit(text_mem_train, y_mem_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(grid.cv_results_)\n",
    "res_pivot = results.pivot_table(values=['mean_test_score', 'mean_train_score'],\n",
    "                                index=[\"param_countvectorizer__ngram_range\", \"param_logisticregression__C\",\n",
    "                                       \"param_countvectorizer__min_df\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_pivot.mean_test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bla = res_pivot.mean_test_score.unstack([\"param_countvectorizer__ngram_range\"])\n",
    "bla = bla.swaplevel().sort_index()\n",
    "bla.index.names = ['min_df', 'C']\n",
    "bla.style.background_gradient(cmap=\"viridis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = grid.best_estimator_.named_steps['logisticregression']\n",
    "feature_names = np.array(grid.best_estimator_.named_steps['countvectorizer'].get_feature_names())\n",
    "n_classes = len(lr.classes_)\n",
    "fig, axes = plt.subplots(n_classes, figsize=(10, 20))\n",
    "for ax, coef, label in zip(axes.ravel(), lr.coef_, lr.classes_):\n",
    "    ax.set_title(label)\n",
    "    plot_important_features(coef, feature_names, top_n=20, ax=ax)\n",
    "    \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hashing Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "hv = HashingVectorizer()\n",
    "X_train = hv.transform(text_train_sub)\n",
    "X_val = hv.transform(text_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegressionCV().fit(X_train, y_train_sub)\n",
    "lr.score(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
